{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import watershed\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.measure import regionprops, label\n",
    "import SimpleITK as sitk\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.morphology import closing, square, remove_small_objects, binary_erosion, disk, binary_dilation\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.color import label2rgb\n",
    "from time import time\n",
    "from skimage.filters import  threshold_otsu, threshold_triangle, gaussian, threshold_local\n",
    "from skimage.morphology import convex_hull_image\n",
    "from skimage.draw import line, polygon\n",
    "\n",
    "print(\"Libraries imported\") # from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_gray_image (img):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.imshow(img, cmap=plt.cm.gray)\n",
    "    ax.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_and_label_dapi(dapi_image, debris_size, min_area_to_keep_cell, erosion_radius, block_size = 251):\n",
    "    ''' Segments the dapi image.\n",
    "    Ipnuts:\n",
    "    \n",
    "    dapi_image: 2-dimensional numpy array (image array)\n",
    "    debris_size: size of the debris to be removed (in pixels)\n",
    "    erosion_radius: radius (in pixels) of the disk to be used for binary ersion to separate connected nuclei\n",
    "    \n",
    "    Outputs:\n",
    "    nuclear_mask: segmented nuclei image\n",
    "    nuclear_labels: labled nuclei\n",
    "    \n",
    "    '''\n",
    "    # locad thresholding to segment the nuclei\n",
    "    adaptive_thresh = threshold_local(dapi_image, block_size = block_size)\n",
    "    seg_dapi = dapi_image > adaptive_thresh\n",
    "    \n",
    "    # use Otsu method to segment the dapi image\n",
    "#     seg_dapi = dapi_image > threshold_otsu(dapi_image)\n",
    "\n",
    "    # fill the holes in the image\n",
    "    nuclear_mask = ndi.binary_fill_holes(seg_dapi)\n",
    "    \n",
    "    # remove small debris from the segmented imaage\n",
    "    seg_dapi = remove_small_objects(seg_dapi, debris_size)\n",
    "\n",
    "    \n",
    "    \n",
    "    nuclear_mask = remove_small_objects(nuclear_mask, min_area_to_keep_cell)\n",
    "    \n",
    "    # erode the image\n",
    "    eroded_mask = binary_erosion(nuclear_mask, disk(erosion_radius))\n",
    "\n",
    "    distance = ndi.distance_transform_edt(eroded_mask)\n",
    "    local_maxi = peak_local_max(distance, indices=False, footprint=np.ones((1, 1)),\n",
    "                                labels=nuclear_mask)\n",
    "    markers = ndi.label(local_maxi)[0]\n",
    "    nuclear_labels = watershed(-distance, markers, mask=nuclear_mask, connectivity=2)\n",
    "    \n",
    "    return nuclear_mask, nuclear_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_big_cells(labeled_img, area_thresh, cir_thresh):\n",
    "    circ = lambda r: (4 * np.pi * r.area) / (r.perimeter * r.perimeter)\n",
    "    big_cells = [(prop.label, prop.area, circ(prop)) for prop in regionprops(labeled_img)\n",
    "                 if prop.area > area_thresh and circ(prop) < cir_thresh]\n",
    "    return big_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cells(label_rem, image):\n",
    "    \n",
    "    relabels, tmp_img = np.zeros_like(image), np.zeros_like(image)\n",
    "    pts = []\n",
    "    row_cords =[]\n",
    "    col_cords = []\n",
    "    for prop in regionprops(label_rem):\n",
    "        x,y = np.int16(np.round(prop.centroid))\n",
    "        row_cords.append(x)\n",
    "        col_cords.append(y)\n",
    "        pts.extend([x,y])\n",
    "    if len(regionprops(label_rem))>2:\n",
    "        rr, cc = polygon(row_cords, col_cords)\n",
    "    else:\n",
    "        rr, cc = line(pts[0], pts[1], pts[2], pts[3])\n",
    "\n",
    "    tmp_img[rr,cc] =1\n",
    "    tmp_img = binary_dilation(tmp_img, disk(10))\n",
    "    tmp_img = convex_hull_image(tmp_img)\n",
    "    split_img = np.logical_and(image, np.logical_not(tmp_img))\n",
    "    distance_rem = ndi.distance_transform_edt(split_img)\n",
    "    local_maxi_rem = peak_local_max(distance_rem, indices=False, footprint=np.ones((1, 1)),\n",
    "                                labels=image)\n",
    "    markers_rem = label(local_maxi_rem, connectivity=2)\n",
    "    labels_rem = watershed(-distance_rem, markers_rem, mask=image, connectivity=2)\n",
    "    return labels_rem\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_final_labels_after_splitting_big_objects(nuclear_labels, big_cells, \n",
    "                                                    ero_rad, min_rem_area, min_area_to_keep_cell):\n",
    "    '''\n",
    "    Inputs:\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    relabels = np.zeros_like(nuclear_labels)\n",
    "\n",
    "    for ii, area, cir in big_cells:\n",
    "        image = nuclear_labels==ii\n",
    "        chull = convex_hull_image(image)\n",
    "        rem = np.logical_and(chull, np.logical_not(image))\n",
    "        eroded_rem = binary_erosion(rem, disk(ero_rad))\n",
    "        eroded_rem = remove_small_objects(eroded_rem, min_rem_area)\n",
    "        label_rem = label(eroded_rem)\n",
    "    #         print(ii, np.max(label_rem))\n",
    "\n",
    "        if np.max(label_rem) >= 2:\n",
    "#             show_gray_image(split_cells(label_rem, image))\n",
    "            relabels = label(relabels + split_cells(label_rem, image))\n",
    "\n",
    "    assigned_relabels = np.zeros_like(relabels)\n",
    "    for p in regionprops(relabels):\n",
    "        if p.label > 0:\n",
    "            assigned_relabels[np.where(relabels==p.label)] = np.max(nuclear_labels) + p.label\n",
    "\n",
    "    label_img = label(nuclear_labels + assigned_relabels)\n",
    "    label_img = remove_small_objects(label_img, min_area_to_keep_cell)\n",
    "#     final_labels = clear_border(label_img)\n",
    "    final_labels = label_img\n",
    "    return final_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide root directory containing images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = r'D:\\Jove_Experiments\\2020_0313_Jove_MCF7_E2_DV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpaths = [os.path.join(root_path,f) for f in os.listdir(root_path) if os.path.isdir(os.path.join(root_path,f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame()\n",
    "for fpath in fpaths:\n",
    "    f_names = [f for f in os.listdir(fpath) if f.endswith('.tif')]\n",
    "    for fname in f_names:\n",
    "        fname_noext = os.path.splitext(fname)[0]\n",
    "        year, mon_date, _, cell_line, treatment, field, _, _, _, wavelength = fname_noext.split('_')\n",
    "        # Store features\n",
    "        features = features.append([{'filename': fname,\n",
    "                                     'filepath': fpath,\n",
    "                                     'date': ('').join([year,mon_date]),\n",
    "                                     'cell_line': cell_line,\n",
    "                                     'treatment': treatment,\n",
    "                                      'field' : field,\n",
    "                                      'wavelength': wavelength,\n",
    "                                     },])\n",
    "    \n",
    "features = features.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'w435': 'dapi', 'w594': 'exon',  'w676': 'intron'}\n",
    "\n",
    "features[\"wavelength\"] = features[\"wavelength\"].map(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User defined parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1\n",
    "erosion_radius = 31\n",
    "debris_size = 100\n",
    "min_area_to_keep_cell = 3001\n",
    "dilation_radius = 100\n",
    "area_thresh =20000 # maximum area of the cell to be considered one cell\n",
    "cir_thresh = 0.70\n",
    "ero_rad = 5 # 5 for DV, radius of the disk to be used for eroading the region (convex hull - roi)\n",
    "min_rem_area = 2 # 2 for DV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_dir = os.path.join(os.path.dirname(root_path), 'Results', 'Segmentation_erosion_radius_'+ str(erosion_radius)\n",
    "                       + '_min_area_' + str(min_area_to_keep_cell) +'_area_thresh_' + str(area_thresh))\n",
    "if not os.path.exists(seg_dir):\n",
    "    os.makedirs(seg_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Jove_Experiments\\2020_0313_Jove_MCF7_E2_DV\\2020_0313_Jove_MCF7_E2_01_R3D_D3D_PRJ_TIFFS 17.607056856155396 seconds\n",
      "D:\\Jove_Experiments\\2020_0313_Jove_MCF7_E2_DV\\2020_0313_Jove_MCF7_E2_02_R3D_D3D_PRJ_TIFFS 70.92408227920532 seconds\n",
      "D:\\Jove_Experiments\\2020_0313_Jove_MCF7_E2_DV\\2020_0313_Jove_MCF7_E2_03_R3D_D3D_PRJ_TIFFS 110.39000272750854 seconds\n",
      "D:\\Jove_Experiments\\2020_0313_Jove_MCF7_E2_DV\\2020_0313_Jove_MCF7_E2_04_R3D_D3D_PRJ_TIFFS 146.34575247764587 seconds\n",
      "D:\\Jove_Experiments\\2020_0313_Jove_MCF7_E2_DV\\2020_0313_Jove_MCF7_E2_05_R3D_D3D_PRJ_TIFFS 191.4196743965149 seconds\n",
      "D:\\Jove_Experiments\\2020_0313_Jove_MCF7_E2_DV\\2020_0313_Jove_MCF7_E2_06_R3D_D3D_PRJ_TIFFS 235.47303986549377 seconds\n",
      "D:\\Jove_Experiments\\2020_0313_Jove_MCF7_E2_DV\\2020_0313_Jove_MCF7_E2_07_R3D_D3D_PRJ_TIFFS 303.4899685382843 seconds\n",
      "D:\\Jove_Experiments\\2020_0313_Jove_MCF7_E2_DV\\2020_0313_Jove_MCF7_E2_08_R3D_D3D_PRJ_TIFFS 353.80703139305115 seconds\n",
      "D:\\Jove_Experiments\\2020_0313_Jove_MCF7_E2_DV\\2020_0313_Jove_MCF7_E2_09_R3D_D3D_PRJ_TIFFS 431.2904062271118 seconds\n",
      "D:\\Jove_Experiments\\2020_0313_Jove_MCF7_E2_DV\\2020_0313_Jove_MCF7_E2_10_R3D_D3D_PRJ_TIFFS 509.09552669525146 seconds\n",
      "D:\\Jove_Experiments\\2020_0313_Jove_MCF7_E2_DV\\2020_0313_Jove_MCF7_Veh_01_R3D_D3D_PRJ_TIFFS 566.8229877948761 seconds\n",
      "D:\\Jove_Experiments\\2020_0313_Jove_MCF7_E2_DV\\2020_0313_Jove_MCF7_Veh_02_R3D_D3D_PRJ_TIFFS 592.6947662830353 seconds\n",
      "D:\\Jove_Experiments\\2020_0313_Jove_MCF7_E2_DV\\2020_0313_Jove_MCF7_Veh_03_R3D_D3D_PRJ_TIFFS 612.3459045886993 seconds\n",
      "D:\\Jove_Experiments\\2020_0313_Jove_MCF7_E2_DV\\2020_0313_Jove_MCF7_Veh_04_R3D_D3D_PRJ_TIFFS 634.9715707302094 seconds\n",
      "D:\\Jove_Experiments\\2020_0313_Jove_MCF7_E2_DV\\2020_0313_Jove_MCF7_Veh_05_R3D_D3D_PRJ_TIFFS 659.4107611179352 seconds\n",
      "D:\\Jove_Experiments\\2020_0313_Jove_MCF7_E2_DV\\2020_0313_Jove_MCF7_Veh_06_R3D_D3D_PRJ_TIFFS 686.4427988529205 seconds\n",
      "D:\\Jove_Experiments\\2020_0313_Jove_MCF7_E2_DV\\2020_0313_Jove_MCF7_Veh_07_R3D_D3D_PRJ_TIFFS 713.9115798473358 seconds\n",
      "D:\\Jove_Experiments\\2020_0313_Jove_MCF7_E2_DV\\2020_0313_Jove_MCF7_Veh_08_R3D_D3D_PRJ_TIFFS 738.2068908214569 seconds\n",
      "D:\\Jove_Experiments\\2020_0313_Jove_MCF7_E2_DV\\2020_0313_Jove_MCF7_Veh_09_R3D_D3D_PRJ_TIFFS 766.9599509239197 seconds\n",
      "D:\\Jove_Experiments\\2020_0313_Jove_MCF7_E2_DV\\2020_0313_Jove_MCF7_Veh_10_R3D_D3D_PRJ_TIFFS 787.7021234035492 seconds\n"
     ]
    }
   ],
   "source": [
    "starting_time = time()\n",
    "summary_df = pd.DataFrame()\n",
    "\n",
    "for fpath in features['filepath'].unique():\n",
    "    df = features[features['filepath'] == fpath]\n",
    "    for channel in df['wavelength']:\n",
    "        sdf = df[df['wavelength']==channel]\n",
    "        fname = sdf['filename'].get_values()[0]\n",
    "        \n",
    "        if channel == 'dapi':\n",
    "            dapi_image =  io.imread(os.path.join(fpath, fname))\n",
    "            # get the nuclear mask and nuclear labels\n",
    "            nuclear_mask, nuclear_labels = segment_and_label_dapi(dapi_image, debris_size, \n",
    "                                                                  min_area_to_keep_cell, erosion_radius)\n",
    "            \n",
    "            # get the big cells (to be split if it contains more than 1 cells)\n",
    "            big_cells = obtain_big_cells(nuclear_labels, area_thresh, cir_thresh)\n",
    "            \n",
    "            # get the final labels after splitting the big cells\n",
    "            final_labels = obtain_final_labels_after_splitting_big_objects(nuclear_labels, big_cells, ero_rad, \n",
    "                                                        min_rem_area, min_area_to_keep_cell)\n",
    "            # nuclei not touching border\n",
    "            non_border_labels = clear_border(final_labels)\n",
    "            nuc_mask = final_labels > 0\n",
    "            \n",
    "            # dialte the nuclear mask to create cell mask\n",
    "            temp_img = binary_dilation(nuc_mask, disk(dilation_radius))\n",
    "            \n",
    "            # use watershed method with final_labels as markers to obtain labeled cell mask\n",
    "            cell_labels = watershed(temp_img, markers=final_labels, mask=temp_img)\n",
    "            \n",
    "            # mark the boundaries of the cell mask\n",
    "            marked_img = mark_boundaries(dapi_image, cell_labels, color=(1, 0, 0), outline_color=(0, 1, 0))\n",
    "            io.imsave(os.path.join(seg_dir, fname), np.uint8(255*nuc_mask))\n",
    "            io.imsave(os.path.join(seg_dir, 'outline_' + fname), np.uint8(marked_img*255))\n",
    "            \n",
    "        elif channel == 'exon':\n",
    "            exon_image =  io.imread(os.path.join(fpath, fname))\n",
    "            # segment using Otsu thresholding\n",
    "            seg_exon = exon_image > threshold_otsu(exon_image)\n",
    "            \n",
    "            io.imsave(os.path.join(seg_dir, fname), np.uint8(255*seg_exon))\n",
    "\n",
    "        elif channel == 'intron':\n",
    "            intron_image = sitk.ReadImage(os.path.join(fpath, fname))\n",
    "            gaussian_blur = sitk.SmoothingRecursiveGaussianImageFilter()\n",
    "            gaussian_blur.SetSigma ( float ( sigma ) )\n",
    "            blur_intron = gaussian_blur.Execute ( intron_image )\n",
    "\n",
    "            max_entropy_filter = sitk.MaximumEntropyThresholdImageFilter()\n",
    "            max_entropy_filter.SetInsideValue(0)\n",
    "            max_entropy_filter.SetOutsideValue(1)\n",
    "            seg = max_entropy_filter.Execute(blur_intron)\n",
    "            seg_intron = sitk.GetArrayFromImage(seg)\n",
    "#             intron_image =  io.imread(os.path.join(fpath, fname))\n",
    "#             blur_intron = gaussian(intron_image, sigma = sigma)\n",
    "#             # segment using Otsu thresholding\n",
    "#             seg_intron = blur_intron > threshold_otsu(blur_intron)\n",
    "            \n",
    "            io.imsave(os.path.join(seg_dir, fname), np.uint8(255*seg_intron))\n",
    "            \n",
    "        else:\n",
    "            print('Different than dapi, exon or intron image found!')\n",
    "    print(fpath, time()-starting_time, 'seconds')       \n",
    "    # save the images\n",
    "    comb_img = np.zeros((seg_exon.shape[0], seg_exon.shape[0], 3))\n",
    "    comb_img[:,:,0] = seg_intron\n",
    "    comb_img[:,:,1] = seg_exon\n",
    "    comb_img[:,:,2] = nuc_mask\n",
    "    marked_img = mark_boundaries(comb_img, cell_labels, color=(1, 1, 1), outline_color=(1, 1, 1))\n",
    "    io.imsave(os.path.join(seg_dir, 'combined_' + fname), np.uint8(marked_img*255))\n",
    "\n",
    "\n",
    "    ### get measurements\n",
    "    # number of cells not toching border\n",
    "    cell_count = np.count_nonzero(np.unique(non_border_labels))\n",
    "    \n",
    "    for cell_prop in regionprops(non_border_labels):\n",
    "        \n",
    "        cell_id = cell_prop.label\n",
    "        \n",
    "        cell_region = cell_labels==cell_id\n",
    "\n",
    "         # label exons in the cell\n",
    "        cell_exon = label(cell_region*seg_exon)\n",
    "\n",
    "        # label intons in the cell\n",
    "        cell_intron = label(cell_region*seg_intron)\n",
    "\n",
    "        # label bursts in the cell\n",
    "        cell_burst = label(cell_region*np.logical_and(seg_intron, seg_exon))\n",
    "\n",
    "        #combine labels\n",
    "        comb_labs =[('green', cell_exon), ('red', cell_intron), ('yellow', cell_burst)]\n",
    "\n",
    "        for col, lab in comb_labs:\n",
    "            for prop in regionprops(lab):\n",
    "                summary_df = summary_df.append([{'cell_id': cell_id,\n",
    "                                'cell_area': cell_prop.area,\n",
    "                                 'cell_centroid': cell_prop.centroid,\n",
    "                                    'dot_area': prop.area,\n",
    "                                    'dot_centroid': prop.centroid,\n",
    "                                    'dot_color' : col,\n",
    "                                    'field' :  df.iloc[0]['field'],\n",
    "                                    'treatment' :  df.iloc[0]['treatment'],\n",
    "                                    'cell_count' : cell_count,\n",
    "                                 },])\n",
    "\n",
    "summary_df = summary_df.reset_index()\n",
    "summary_df.to_excel(os.path.join(seg_dir,'JOVE_exp_summary.xlsx'))\n",
    "# print('Total time taken is', time()- starting_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = summary_df['treatment'].unique()\n",
    "requirements = [('green', 0), ('red', 9), ('yellow', 4)] # ('green', 0): dot color and dot area threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame()\n",
    "for condition in conditions:\n",
    "    for dot_col, dot_area_thres in requirements:\n",
    "        num_cells, num_dots =0, 0\n",
    "\n",
    "        for field in summary_df['field'].unique():\n",
    "            df = summary_df[(summary_df['field'] == field) & \n",
    "                            (summary_df['treatment'] == condition) &\n",
    "                           (summary_df['dot_color'] == dot_col)]\n",
    "        #     print(field, df['cell_count'].unique())\n",
    "            cell_count = df['cell_count'].unique()[0]\n",
    "            num_cells = num_cells + cell_count\n",
    "            num_dots = num_dots + df[df['dot_area']>dot_area_thres]['dot_area'].count()\n",
    "            \n",
    "        summary = summary.append([{'number of dots': num_dots,\n",
    "                                   'number of cells': num_cells,\n",
    "                            'dot_area_thres': dot_area_thres,\n",
    "                                'dot_color' : dot_col,\n",
    "                                'field' :  field,\n",
    "                                'treatment' :  condition,\n",
    "                             },])\n",
    "\n",
    "summary = summary.reset_index()\n",
    "#         print('Treatment :', condition, '\\n',\n",
    "#               'dot color :', dot_col, '\\n'\n",
    "#               'number of cells :', num_cells, '\\n', \n",
    "#               'number of dots :', num_dots, '\\n',\n",
    "#              'average dots per cells :', num_dots/num_cells, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_excel(os.path.join(os.path.dirname(seg_dir),'Segmentation_'+ str(erosion_radius)\n",
    "                       + '_min_area_' + str(min_area_to_keep_cell) +'_area_thresh_' + str(area_thresh)+'.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_cell = pd.DataFrame()\n",
    "for condition in conditions:\n",
    "    cell_num = 0\n",
    "    \n",
    "    for field in summary_df['field'].unique():\n",
    "        df = summary_df[(summary_df['field'] == field) & \n",
    "                            (summary_df['treatment'] == condition)]\n",
    "        \n",
    "        cell_count = df['cell_count'].unique()[0]\n",
    "        \n",
    "        for count, cell in enumerate(df['cell_id'].unique()):\n",
    "            cell_num = cell_num + 1\n",
    "            \n",
    "            n_green = len(df[(df['dot_color'] == 'green') & (df['dot_area']>0) & (df['cell_id'] == cell)])\n",
    "            n_red = len(df[(df['dot_color'] == 'red') & (df['dot_area']>4) & (df['cell_id'] == cell)])\n",
    "            n_yellow = len(df[(df['dot_color'] == 'yellow') & (df['dot_area']>4) & (df['cell_id'] == cell)])\n",
    "            \n",
    "            summary_cell = summary_cell.append([{'num_green_dots': n_green,\n",
    "                                                 'num_red_dots': n_red,\n",
    "                                                 'num_yellow_dots': n_yellow,\n",
    "                                                      'cell_num': cell_num,\n",
    "                                                 'treatment' :  condition,\n",
    "                                                         },])\n",
    "\n",
    "            \n",
    "        while count < cell_count:\n",
    "            count = count + 1\n",
    "            n_green,n_red, n_yellow = 0, 0, 0\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "summary_cell = summary_cell.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_cell.to_excel(os.path.join(os.path.dirname(seg_dir),'Summary_'+ str(erosion_radius)\n",
    "                       + '_min_area_' + str(min_area_to_keep_cell) +'_area_thresh_' + str(area_thresh)+'.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'cell_num',\n",
       " 'num_green_dots',\n",
       " 'num_red_dots',\n",
       " 'num_yellow_dots',\n",
       " 'treatment']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(summary_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly_express as px\n",
    "from plotly.offline import plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = px.histogram(summary_cell, x=\"num_yellow_dots\", color='treatment')\n",
    "plot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
